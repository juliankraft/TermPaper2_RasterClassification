@article{adegunReviewDeepLearning2023,
  title = {Review of Deep Learning Methods for Remote Sensing Satellite Images Classification: Experimental Survey and Comparative Analysis},
  shorttitle = {Review of Deep Learning Methods for Remote Sensing Satellite Images Classification},
  author = {Adegun, Adekanmi Adeyinka and Viriri, Serestina and Tapamo, Jules-Raymond},
  date = {2023-06-02},
  journaltitle = {Journal of Big Data},
  shortjournal = {Journal of Big Data},
  volume = {10},
  number = {1},
  pages = {93},
  issn = {2196-1115},
  doi = {10.1186/s40537-023-00772-x},
  url = {https://doi.org/10.1186/s40537-023-00772-x},
  urldate = {2024-11-15},
  abstract = {Classification and analysis of high-resolution satellite images using conventional techniques have been limited. This is due to the complex characteristics of the imagery. These images are characterized by features such as spectral signatures, complex texture and shape, spatial relationships and temporal changes. In this research, we present the performance evaluation and analysis of deep learning approaches based on Convolutional Neural Networks and vision transformer towards achieving efficient classification of remote sensing satellite images. The CNN-based models explored include ResNet, DenseNet, EfficientNet, VGG and InceptionV3. The models were evaluated on three publicly available EuroSAT, UCMerced-LandUse and NWPU-RESISC45 datasets containing categories of images. The models achieve promising results in accuracy, recall, precision and F1-score. This performance demonstrates the feasibility of Deep Learning approaches in learning the complex and in-homogeneous features of the high-resolution remote sensing images.},
  keywords = {Convolutional neural networks,Deep learning,Image classification,Remote sensing images,Satellite images,Vision Transformer},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\5RRFZJF3\\Adegun et al. - 2023 - Review of deep learning methods for remote sensing.pdf;C\:\\Users\\kraft\\Zotero\\storage\\NHRVA2UG\\s40537-023-00772-x.html}
}

@article{alemTransferLearningModels2022,
  title = {Transfer {{Learning Models}} for {{Land Cover}} and {{Land Use Classification}} in {{Remote Sensing Image}}},
  author = {Alem, Abebaw and Kumar, Shailender},
  date = {2022-12-31},
  journaltitle = {Applied Artificial Intelligence},
  shortjournal = {Applied Artificial Intelligence},
  volume = {36},
  number = {1},
  pages = {2014192},
  issn = {0883-9514, 1087-6545},
  doi = {10.1080/08839514.2021.2014192},
  url = {https://www.tandfonline.com/doi/full/10.1080/08839514.2021.2014192},
  urldate = {2025-01-16},
  langid = {english},
  file = {C:\Users\kraft\Zotero\storage\KFRYXI78\Alem and Kumar - 2022 - Transfer Learning Models for Land Cover and Land U.pdf}
}

@article{davydzenkaImprovingRemoteSensing2022,
  title = {Improving Remote Sensing Classification: {{A}} Deep-Learning-Assisted Model},
  shorttitle = {Improving Remote Sensing Classification},
  author = {Davydzenka, Tsimur and Tahmasebi, Pejman and Carroll, Mark},
  date = {2022-07-01},
  journaltitle = {Computers \& Geosciences},
  shortjournal = {Computers \& Geosciences},
  volume = {164},
  pages = {105123},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2022.105123},
  url = {https://www.sciencedirect.com/science/article/pii/S0098300422000814},
  urldate = {2024-12-10},
  abstract = {In many industries and applications, obtaining and classifying remote sensing imagery plays a crucial role. The accuracy of classification, in particular the machine learning methods, mainly depends on a multitude of factors, among which one of the most important ones is the amount of training data. Obtaining sufficient amounts of training data, however, can be very difficult or costly, and one must find alternative ways to improve the accuracy of predictions. To this end, a possible solution that we provide in this study is to use a stochastic method for producing variations of the training images that will retain the important class-wide features and thereby enrich the machine learning's “understanding” of the variabilities. As such, we applied a stochastic algorithm to produce additional realizations of the limited input imagery and thereby significantly increase the final overall accuracy in a deep learning method. We found that by enlarging the initial training set by additional realizations, we are able to consistently improve classification accuracy, compared with generic image augmentation approaches. The results of this study show that there is a great opportunity to increase the accuracy of predictions when enough data are not available.},
  keywords = {Data augmentation,Image classification,Machine learning,Remote sensing. introduction}
}

@online{DeeplearningmodelsREADMEmdMaster,
  title = {Deep-Learning-Models/{{README}}.Md at Master · Fchollet/Deep-Learning-Models},
  url = {https://github.com/fchollet/deep-learning-models/blob/master/README.md},
  urldate = {2024-12-10},
  file = {C:\Users\kraft\Zotero\storage\RECC7SU6\README.html}
}

@book{Goodfellow-et-al-201,
  title = {Deep {{Learning}}},
  author = {Goodfellow, Ian and Benigo, Yoshua and Courville, Aaron},
  date = {2016},
  publisher = {MIT Press},
  url = {http://www.deeplearningbook.org}
}

@online{heDeepResidualLearning2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2015-12-10},
  eprint = {1512.03385},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1512.03385},
  url = {http://arxiv.org/abs/1512.03385},
  urldate = {2024-12-10},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\9RHZS6WV\\He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf;C\:\\Users\\kraft\\Zotero\\storage\\ZNMVPPLM\\1512.html}
}

@article{kadhimAdvancesRemoteSensing2016,
  title = {Advances in Remote Sensing Applications for Urban Sustainability},
  author = {Kadhim, Nada and Mourshed, Monjur and Bray, Michaela},
  date = {2016-10-18},
  journaltitle = {Euro-Mediterranean Journal for Environmental Integration},
  shortjournal = {Euro-Mediterr J Environ Integr},
  volume = {1},
  number = {1},
  pages = {7},
  issn = {2365-7448},
  doi = {10.1007/s41207-016-0007-4},
  url = {https://doi.org/10.1007/s41207-016-0007-4},
  urldate = {2025-01-16},
  abstract = {It is essential to monitor urban evolution at spatial and temporal scales to improve our understanding of the changes in cities and their impact on natural resources and environmental systems. Various aspects of remote sensing are routinely used to detect and map features and changes on land and sea surfaces, and in the atmosphere that affect urban sustainability. We provide a critical and comprehensive review of the characteristics of remote sensing systems, and in particular the trade-offs between various system parameters, as well as their use in two key research areas: (a) issues resulting from the expansion of urban environments, and (b) sustainable urban development. The analysis identifies three key trends in the existing literature: (a) the integration of heterogeneous remote sensing data, primarily for investigating or modelling urban environments as a complex system, (b) the development of new algorithms for effective extraction of urban features, and (c) the improvement in the accuracy of traditional spectral-based classification algorithms for addressing the spectral heterogeneity within urban areas. Growing interests in renewable energy have also resulted in the increased use of remote sensing—for planning, operation, and maintenance of energy infrastructures, in particular the ones with spatial variability, such as solar, wind, and geothermal energy. The proliferation of sustainability thinking in all facets of urban development and management also acts as a catalyst for the increased use of, and advances in, remote sensing for urban applications.},
  langid = {english},
  keywords = {Environmental sustainability,Remote sensing applications,Remote sensing systems,Sustainable cities,Urban environments},
  file = {C:\Users\kraft\Zotero\storage\MQUZUV5D\Kadhim et al. - 2016 - Advances in remote sensing applications for urban .pdf}
}

@article{kampourakiApplicationRemoteSensing,
  title = {The Application of Remote Sensing to Identify and Measure Sealed Areas in Urban Environments},
  author = {Kampouraki, M and Wood, G A and Brewer, T},
  abstract = {Numerous studies have used satellite images for mapping urban land cover and land use along with modelling green spaces and surface impermeability. Recently, monitoring the percentage of sealed soils in urban environments is of great interest as a key indicator of sustainable landuse. The aim of this research is to identify an appropriate methodology to classify sealed soil and green space surfaces in urban environments with the use of satellite remotely sensed data. The study area is the city of Cambridge, UK. The percentage of sealed soils, within 18 randomly selected sample segments (250 x 250 m), was interpreted visually from the aerial photography and the Ordnance Survey (OS) MasterMap polygons attributed accordingly; the percentage was limited to a precision of 25\%, i.e. 0, 25, 50, 75 and 100\%. The results were compared with a maximum likelihood classification of Normalised Difference Vegetation Index (NDVI) images derived from QuickBird data integrated with the OS MasterMap and summarised using confusion matrices. The overall mapping accuracy was estimated to be approximately 75\%. The low map accuracy is due to coarse precision of the aerial photo interpretation (API) and the use of pixel based classification procedures. The described methodology are the preliminary results of an on going research study. In the future, object-based classifiers (eCognition) will be investigated to provide an objective approach of the visual interpretation and improve efficiency and accuracy. eCognition is also anticipated to be used as the main classifier of the satellite image analysis.},
  langid = {english},
  file = {C:\Users\kraft\Zotero\storage\43U4AN6H\Kampouraki et al. - THE APPLICATION OF REMOTE SENSING TO IDENTIFY AND .pdf}
}

@article{liDeepLearningRemote2018,
  title = {Deep Learning for Remote Sensing Image Classification: {{A}} Survey},
  shorttitle = {Deep Learning for Remote Sensing Image Classification},
  author = {Li, Ying and Zhang, Haokui and Xue, Xizhe and Jiang, Yenan and Shen, Qiang},
  date = {2018},
  journaltitle = {WIREs Data Mining and Knowledge Discovery},
  volume = {8},
  number = {6},
  pages = {e1264},
  issn = {1942-4795},
  doi = {10.1002/widm.1264},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1264},
  urldate = {2024-12-10},
  abstract = {Remote sensing (RS) image classification plays an important role in the earth observation technology using RS data, having been widely exploited in both military and civil fields. However, due to the characteristics of RS data such as high dimensionality and relatively small amounts of labeled samples available, performing RS image classification faces great scientific and practical challenges. In recent years, as new deep learning (DL) techniques emerge, approaches to RS image classification with DL have achieved significant breakthroughs, offering novel opportunities for the research and development of RS image classification. In this paper, a brief overview of typical DL models is presented first. This is followed by a systematic review of pixel-wise and scene-wise RS image classification approaches that are based on the use of DL. A comparative analysis regarding the performances of typical DL-based RS methods is also provided. Finally, the challenges and potential directions for further research are discussed. This article is categorized under: Application Areas {$>$} Science and Technology Technologies {$>$} Classification},
  langid = {english},
  keywords = {convolutional neural network,deep belief network,deep learning,pixel-wise classification,remote sensing image,scene classification,stacked auto-encoder},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\CLS243QC\\Li et al. - 2018 - Deep learning for remote sensing image classificat.pdf;C\:\\Users\\kraft\\Zotero\\storage\\RNWM2CRC\\widm.html}
}

@article{maDeepLearningRemote2019,
  title = {Deep Learning in Remote Sensing Applications: {{A}} Meta-Analysis and Review},
  shorttitle = {Deep Learning in Remote Sensing Applications},
  author = {Ma, Lei and Liu, Yu and Zhang, Xueliang and Ye, Yuanxin and Yin, Gaofei and Johnson, Brian Alan},
  date = {2019-06-01},
  journaltitle = {ISPRS Journal of Photogrammetry and Remote Sensing},
  shortjournal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume = {152},
  pages = {166--177},
  issn = {0924-2716},
  doi = {10.1016/j.isprsjprs.2019.04.015},
  url = {https://www.sciencedirect.com/science/article/pii/S0924271619301108},
  urldate = {2025-01-16},
  abstract = {Deep learning (DL) algorithms have seen a massive rise in popularity for remote-sensing image analysis over the past few years. In this study, the major DL concepts pertinent to remote-sensing are introduced, and more than 200 publications in this field, most of which were published during the last two years, are reviewed and analyzed. Initially, a meta-analysis was conducted to analyze the status of remote sensing DL studies in terms of the study targets, DL model(s) used, image spatial resolution(s), type of study area, and level of classification accuracy achieved. Subsequently, a detailed review is conducted to describe/discuss how DL has been applied for remote sensing image analysis tasks including image fusion, image registration, scene classification, object detection, land use and land cover (LULC) classification, segmentation, and object-based image analysis (OBIA). This review covers nearly every application and technology in the field of remote sensing, ranging from preprocessing to mapping. Finally, a conclusion regarding the current state-of-the art methods, a critical conclusion on open challenges, and directions for future research are presented.},
  keywords = {Deep learning (DL),LULC classification,Object detection,Remote sensing,Scene classification},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\V9XX3CXW\\Ma et al. - 2019 - Deep learning in remote sensing applications A me.pdf;C\:\\Users\\kraft\\Zotero\\storage\\XXSMDPIS\\S0924271619301108.html}
}

@article{maggioriConvolutionalNeuralNetworks2017,
  title = {Convolutional {{Neural Networks}} for {{Large-Scale Remote-Sensing Image Classification}}},
  author = {Maggiori, Emmanuel and Tarabalka, Yuliya and Charpiat, Guillaume and Alliez, Pierre},
  date = {2017-02},
  journaltitle = {IEEE Transactions on Geoscience and Remote Sensing},
  volume = {55},
  number = {2},
  pages = {645--657},
  issn = {1558-0644},
  doi = {10.1109/TGRS.2016.2612821},
  url = {https://ieeexplore.ieee.org/document/7592858},
  urldate = {2025-01-16},
  abstract = {We propose an end-to-end framework for the dense, pixelwise classification of satellite imagery with convolutional neural networks (CNNs). In our framework, CNNs are directly trained to produce classification maps out of the input images. We first devise a fully convolutional architecture and demonstrate its relevance to the dense classification problem. We then address the issue of imperfect training data through a two-step training approach: CNNs are first initialized by using a large amount of possibly inaccurate reference data, and then refined on a small amount of accurately labeled data. To complete our framework, we design a multiscale neuron module that alleviates the common tradeoff between recognition and precise localization. A series of experiments show that our networks consider a large amount of context to provide fine-grained classification maps.},
  eventtitle = {{{IEEE Transactions}} on {{Geoscience}} and {{Remote Sensing}}},
  keywords = {Biological neural networks,Classification,Context,convolutional neural networks (CNNs),deep learning,Neurons,Remote sensing,satellite images,Satellites,Training,Training data},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\AFPLHBXN\\Maggiori et al. - 2017 - Convolutional Neural Networks for Large-Scale Remo.pdf;C\:\\Users\\kraft\\Zotero\\storage\\FB6NIKNP\\7592858.html}
}

@inproceedings{natyaDeepTransferLearning2022,
  title = {Deep {{Transfer Learning}} with {{RESNET}} for {{Remote Sensing Scene Classification}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Data Science}} and {{Information System}} ({{ICDSIS}})},
  author = {Natya, S and Manu, C and Anand, Ashutosh},
  date = {2022-07},
  pages = {1--6},
  doi = {10.1109/ICDSIS55133.2022.9915967},
  url = {https://ieeexplore.ieee.org/document/9915967?utm_source=chatgpt.com},
  urldate = {2025-01-16},
  abstract = {This paper explains a comparative examination of aerial images for Land-Use and Land-Cover (LU\&LC) classification, focusing on urban regions where scattering properties are nearly equivalent. To attain better performance metrics, a complete analysis was carried out, in which two ResNet-based models were applied to the RSI-CB128 dataset utilizing three different optimizers: Adam, SGDM, and RMSProp. Both ResNet models have been used on five different classes of the dataset with three different optimisers. RMSprop has the best accuracy with moderate simulation time in the case of ResNetl8, while in the case of ResNet50, SGDM has the best accuracy of 95.8\% with the lowest simulation time.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Data Science}} and {{Information System}} ({{ICDSIS}})},
  keywords = {Data science,deep learning,Focusing,Image analysis,image classification,land use and land cover,Measurement,Remote sensing,residual network,Scattering,Training,Transfer learning},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\5D2ZDMQZ\\Natya et al. - 2022 - Deep Transfer Learning with RESNET for Remote Sens.pdf;C\:\\Users\\kraft\\Zotero\\storage\\6A8FPJSM\\9915967.html}
}

@article{radovicObjectRecognitionAerial2017,
  title = {Object {{Recognition}} in {{Aerial Images Using Convolutional Neural Networks}}},
  author = {Radovic, Matija and Adarkwa, Offei and Wang, Qiaosong},
  date = {2017-06},
  journaltitle = {Journal of Imaging},
  volume = {3},
  number = {2},
  pages = {21},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2313-433X},
  doi = {10.3390/jimaging3020021},
  url = {https://www.mdpi.com/2313-433X/3/2/21},
  urldate = {2025-01-16},
  abstract = {There are numerous applications of unmanned aerial vehicles (UAVs) in the management of civil infrastructure assets. A few examples include routine bridge inspections, disaster management, power line surveillance and traffic surveying. As UAV applications become widespread, increased levels of autonomy and independent decision-making are necessary to improve the safety, efficiency, and accuracy of the devices. This paper details the procedure and parameters used for the training of convolutional neural networks (CNNs) on a set of aerial images for efficient and automated object recognition. Potential application areas in the transportation field are also highlighted. The accuracy and reliability of CNNs depend on the network’s training and the selection of operational parameters. This paper details the CNN training procedure and parameter selection. The object recognition results show that by selecting a proper set of parameters, a CNN can detect and classify objects with a high level of accuracy (97.5\%) and computational efficiency. Furthermore, using a convolutional neural network implemented in the “YOLO” (“You Only Look Once”) platform, objects can be tracked, detected (“seen”), and classified (“comprehended”) from video feeds supplied by UAVs in real-time.},
  issue = {2},
  langid = {english},
  keywords = {convolutional neural networks,object recognition and detection,Unmanned Aerial Vehicle (UAV)},
  file = {C:\Users\kraft\Zotero\storage\Q55Z8CJU\Radovic et al. - 2017 - Object Recognition in Aerial Images Using Convolut.pdf}
}

@online{RecipeTrainingNeural,
  title = {A {{Recipe}} for {{Training Neural Networks}}},
  url = {https://karpathy.github.io/2019/04/25/recipe/},
  urldate = {2024-12-13},
  file = {C:\Users\kraft\Zotero\storage\T6RG58J7\recipe.html}
}

@online{ResNetPyTorchREADMEmdMaster,
  title = {{{ResNet-PyTorch}}/{{README}}.Md at Master · {{JayPatwardhan}}/{{ResNet-PyTorch}}},
  url = {https://github.com/JayPatwardhan/ResNet-PyTorch/blob/master/README.md},
  urldate = {2024-12-10},
  file = {C:\Users\kraft\Zotero\storage\66ZIIF66\README.html}
}

@software{SatelliteimagedeeplearningTechniques2024,
  title = {Satellite-Image-Deep-Learning/Techniques},
  date = {2024-11-15T07:17:33Z},
  origdate = {2018-04-16T08:42:09Z},
  url = {https://github.com/satellite-image-deep-learning/techniques},
  urldate = {2024-11-15},
  abstract = {Techniques for deep learning with satellite \& aerial imagery},
  organization = {satellite-image-deep-learning},
  keywords = {convolutional-neural-networks,dataset,datasets,deep-learning,deep-neural-networks,earth-observation,image-classification,keras,machine-learning,object-detection,python,pytorch,remote-sensing,satellite-data,satellite-imagery,satellite-images,sentinel,tensorflow}
}

@online{ScikitlearnMachineLearning,
  title = {Scikit-Learn: Machine Learning in {{Python}}},
  url = {https://scikit-learn.org/stable/},
  urldate = {2025-01-15},
  file = {C:\Users\kraft\Zotero\storage\2BVVNTFF\stable.html}
}

@online{simonyanVeryDeepConvolutional2015,
  title = {Very {{Deep Convolutional Networks}} for {{Large-Scale Image Recognition}}},
  author = {Simonyan, Karen and Zisserman, Andrew},
  date = {2015-04-10},
  eprint = {1409.1556},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1409.1556},
  url = {http://arxiv.org/abs/1409.1556},
  urldate = {2024-12-10},
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\FPXFNITT\\Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf;C\:\\Users\\kraft\\Zotero\\storage\\6J7UKGFV\\1409.html}
}

@article{singhPixelBasedClassification2021a,
  title = {Pixel Based Classification for {{Landsat}} 8 {{OLI}} Multispectral Satellite Images Using Deep Learning Neural Network},
  author = {Singh, Mohan and Tyagi, Kapil Dev},
  date = {2021-11-01},
  journaltitle = {Remote Sensing Applications: Society and Environment},
  shortjournal = {Remote Sensing Applications: Society and Environment},
  volume = {24},
  pages = {100645},
  issn = {2352-9385},
  doi = {10.1016/j.rsase.2021.100645},
  url = {https://www.sciencedirect.com/science/article/pii/S2352938521001816},
  urldate = {2024-11-15},
  abstract = {In satellite image analysis, classification of objects appearing in an image is a major step of information extraction. The information acquired from the satellite image can be used to provide the solution of various remote sensing problems such as agricultural challenges, natural hazards, and environmental monitoring etc. The most of the conventional classifiers used to classify satellite images do not provide realistic classification with high accuracy. Therefore, for achieving realistic and more accurate classification of the satellite images is still a challenging task. Machine intelligence is being harnessed to solve this task. In this paper, we present a novel machine intelligence pixel based approach for multispectral satellite image classification. We have proposed a machine intelligence deep learning neural network with five hidden layers and seven training features for satellite images classification. The model is tested on four types of data sets namely three classes, four classes, five classes and seven classes. Accuracy of 99.99\%, 99.96\%, 99.45\% and 98.03\% has been obtained on four test data sets respectively. In all cases, it is observed that the proposed method provides 8.52\% higher accuracy than previously proposed classifiers.},
  keywords = {Artificial neural network (ANN),Deep learning and remote sensing,Landsat 8 OLI image dataset,Pixel based classification},
  file = {C:\Users\kraft\Zotero\storage\2Q926B5H\S2352938521001816.html}
}

@dataset{swisstopoSWISSIMAGERS2024,
  title = {{{SWISSIMAGE RS}}},
  author = {SwissTopo},
  date = {2024},
  url = {https://www.swisstopo.admin.ch/de/orthobilder-swissimage-rs},
  urldate = {2024-11-15},
  abstract = {Das Bildprodukt SWISSIMAGE RS enthält eine bisher unerreichte Informationsfülle. Durch die Kombination von vier Kanälen (Nahes Infrarot, Rot, Grün, Blau) bieten diese Einzelorthofotos eine optimale Grundlage für verschiedenste Fachanwendungen.},
  file = {C:\Users\kraft\Zotero\storage\86KKSQYE\orthobilder-swissimage-rs.html}
}

@article{thapaDeepLearningRemote2023,
  title = {Deep {{Learning}} for {{Remote Sensing Image Scene Classification}}: {{A Review}} and {{Meta-Analysis}}},
  shorttitle = {Deep {{Learning}} for {{Remote Sensing Image Scene Classification}}},
  author = {Thapa, Aakash and Horanont, Teerayut and Neupane, Bipul and Aryal, Jagannath},
  date = {2023-01},
  journaltitle = {Remote Sensing},
  volume = {15},
  number = {19},
  pages = {4804},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs15194804},
  url = {https://www.mdpi.com/2072-4292/15/19/4804},
  urldate = {2024-12-10},
  abstract = {Remote sensing image scene classification with deep learning (DL) is a rapidly growing field that has gained significant attention in the past few years. While previous review papers in this domain have been confined to 2020, an up-to-date review to show the progression of research extending into the present phase is lacking. In this review, we explore the recent articles, providing a thorough classification of approaches into three main categories: Convolutional Neural Network (CNN)-based, Vision Transformer (ViT)-based, and Generative Adversarial Network (GAN)-based architectures. Notably, within the CNN-based category, we further refine the classification based on specific methodologies and techniques employed. In addition, a novel and rigorous meta-analysis is performed to synthesize and analyze the findings from 50 peer-reviewed journal articles to provide valuable insights in this domain, surpassing the scope of existing review articles. Our meta-analysis shows that the most adopted remote sensing scene datasets are AID (41 articles) and NWPU-RESISC45 (40). A notable paradigm shift is seen towards the use of transformer-based models (6) starting from 2021. Furthermore, we critically discuss the findings from the review and meta-analysis, identifying challenges and future opportunities for improvement in this domain. Our up-to-date study serves as an invaluable resource for researchers seeking to contribute to this growing area of research.},
  issue = {19},
  langid = {english},
  keywords = {convolutional neural networks,deep learning,meta-analysis,remote sensing,scene classification},
  file = {C:\Users\kraft\Zotero\storage\SPZWVD52\Thapa et al. - 2023 - Deep Learning for Remote Sensing Image Scene Class.pdf}
}

@online{VisionTorchvisionModels,
  title = {Vision/Torchvision/Models/Vgg.Py at Main · Pytorch/Vision},
  url = {https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py},
  urldate = {2024-12-10},
  abstract = {Datasets, Transforms and Models specific to Computer Vision - pytorch/vision},
  langid = {english},
  organization = {GitHub}
}

@online{VisionTorchvisionModelsa,
  title = {Vision/Torchvision/Models/Resnet.Py at Main · Pytorch/Vision},
  url = {https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py},
  urldate = {2024-12-13},
  abstract = {Datasets, Transforms and Models specific to Computer Vision - pytorch/vision},
  langid = {english},
  organization = {GitHub}
}

@article{xieScaleFreeConvolutionalNeural2019,
  title = {Scale-{{Free Convolutional Neural Network}} for {{Remote Sensing Scene Classification}}},
  author = {Xie, Jie and He, Nanjun and Fang, Leyuan and Plaza, Antonio},
  date = {2019-09},
  journaltitle = {IEEE Transactions on Geoscience and Remote Sensing},
  volume = {57},
  number = {9},
  pages = {6916--6928},
  issn = {1558-0644},
  doi = {10.1109/TGRS.2019.2909695},
  url = {https://ieeexplore.ieee.org/abstract/document/8699111},
  urldate = {2024-12-10},
  abstract = {Fine-tuning of pretrained convolutional neural networks (CNNs) has been proven to be an effective strategy for remote sensing image scene classification, particularly when a limited number of labeled data sets are available for training purposes. However, such a fine-tuning process often needs that the input images are resized into a fixed size to generate input vectors of the size required by fully connected layers (FCLs) in the pretrained CNN model. Such a resizing process often discards key information in the scenes and thus deteriorates the classification performance. To address this issue, in this paper, we introduce a scale-free CNN (SF-CNN) for remote sensing scene classification. Specifically, the FCLs in the CNN model are first converted into convolutional layers, which not only allow the input images to be of arbitrary sizes but also retain the ability to extract discriminative features using a traditional sliding-window-based strategy. Then, a global average pooling (GAP) layer is added after the final convolutional layer so that input images of arbitrary size can be mapped to feature maps of uniform size. Finally, we utilize the resulting feature maps to create a new FCL that is fed to a softmax layer for final classification. Our experimental results conducted using several real data sets demonstrate the superiority of the proposed SF-CNN method over several well-known classification methods, including pretrained CNN-based ones.},
  eventtitle = {{{IEEE Transactions}} on {{Geoscience}} and {{Remote Sensing}}},
  keywords = {Data models,Feature extraction,Free-scale convolutional neural networks (CNNs),fully connected layers (FCLs),Image color analysis,Iron,Kernel,Remote sensing,remote sensing scene classification,Semantics},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\MMUBGZ2M\\Xie et al. - 2019 - Scale-Free Convolutional Neural Network for Remote.pdf;C\:\\Users\\kraft\\Zotero\\storage\\BGYY79MZ\\8699111.html}
}

@article{zhengHighSpatialResolution2023,
  title = {High Spatial Resolution Remote Sensing Image Segmentation Based on the Multiclassification Model and the Binary Classification Model},
  author = {Zheng, Xiaoxiong and Chen, Tao},
  date = {2023-02-01},
  journaltitle = {Neural Computing and Applications},
  shortjournal = {Neural Comput \& Applic},
  volume = {35},
  number = {5},
  pages = {3597--3604},
  issn = {1433-3058},
  doi = {10.1007/s00521-020-05561-8},
  url = {https://doi.org/10.1007/s00521-020-05561-8},
  urldate = {2025-01-16},
  abstract = {Semantic segmentation technology is an important step in the interpretation of remote sensing images. High spatial resolution remote sensing images have clear features. Traditional image segmentation methods cannot fully represent the information in high spatial resolution images and tend to yield unsatisfactory segmentation accuracy. With the rapid development of deep learning, many researchers have tried to use deep learning algorithms for remote sensing image segmentation. This paper uses U-Net for multiclassification and binary classification of Gaofen-2 high spatial resolution remote sensing image data. Six types of features, which were build-up, farmland, water, meadow, forest and others, were labeled in the image. A “neighborhood voting” method was used to determine the category of uncertain pixels based on spatial heterogeneity and homogeneity. Through U-Net neural network multiclassification, the overall accuracy of the training data is 93.83\%; the overall accuracy of the test data is 82.27\%; and the test accuracy of the binary classification algorithm is 79.75\%. The results show that the two models yield high accuracy and credibility in remote sensing image segmentation.},
  langid = {english},
  keywords = {Artificial Intelligence,High spatial resolution remote sensing image,Neighborhood voting,Semantic segmentation,U-Net},
  file = {C:\Users\kraft\Zotero\storage\7Z7YTDP2\Zheng and Chen - 2023 - High spatial resolution remote sensing image segme.pdf}
}

@article{zhuDeepLearningRemote2017,
  title = {Deep {{Learning}} in {{Remote Sensing}}: {{A Comprehensive Review}} and {{List}} of {{Resources}}},
  shorttitle = {Deep {{Learning}} in {{Remote Sensing}}},
  author = {Zhu, Xiao Xiang and Tuia, Devis and Mou, Lichao and Xia, Gui-Song and Zhang, Liangpei and Xu, Feng and Fraundorfer, Friedrich},
  date = {2017-12},
  journaltitle = {IEEE Geoscience and Remote Sensing Magazine},
  volume = {5},
  number = {4},
  pages = {8--36},
  issn = {2168-6831},
  doi = {10.1109/MGRS.2017.2762307},
  url = {https://ieeexplore.ieee.org/document/8113128},
  urldate = {2025-01-16},
  abstract = {Central to the looming paradigm shift toward data-intensive science, machine-learning techniques are becoming increasingly important. In particular, deep learning has proven to be both a major breakthrough and an extremely powerful tool in many fields. Shall we embrace deep learning as the key to everything? Or should we resist a black-box solution? These are controversial issues within the remote-sensing community. In this article, we analyze the challenges of using deep learning for remote-sensing data analysis, review recent advances, and provide resources we hope will make deep learning in remote sensing seem ridiculously simple. More importantly, we encourage remote-sensing scientists to bring their expertise into deep learning and use it as an implicit general model to tackle unprecedented, large-scale, influential challenges, such as climate change and urbanization.},
  eventtitle = {{{IEEE Geoscience}} and {{Remote Sensing Magazine}}},
  keywords = {Climate change,Computer vision,Feature extraction,Hyperspectral imaging,Machine learning,Remote sensing,Tutorials},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\97XA2WRB\\Zhu et al. - 2017 - Deep Learning in Remote Sensing A Comprehensive R.pdf;C\:\\Users\\kraft\\Zotero\\storage\\UI9J52Z3\\8113128.html}
}
