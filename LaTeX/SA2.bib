@article{adegunReviewDeepLearning2023,
  title = {Review of Deep Learning Methods for Remote Sensing Satellite Images Classification: Experimental Survey and Comparative Analysis},
  shorttitle = {Review of Deep Learning Methods for Remote Sensing Satellite Images Classification},
  author = {Adegun, Adekanmi Adeyinka and Viriri, Serestina and Tapamo, Jules-Raymond},
  date = {2023-06-02},
  journaltitle = {Journal of Big Data},
  shortjournal = {Journal of Big Data},
  volume = {10},
  number = {1},
  pages = {93},
  issn = {2196-1115},
  doi = {10.1186/s40537-023-00772-x},
  url = {https://doi.org/10.1186/s40537-023-00772-x},
  urldate = {2024-11-15},
  abstract = {Classification and analysis of high-resolution satellite images using conventional techniques have been limited. This is due to the complex characteristics of the imagery. These images are characterized by features such as spectral signatures, complex texture and shape, spatial relationships and temporal changes. In this research, we present the performance evaluation and analysis of deep learning approaches based on Convolutional Neural Networks and vision transformer towards achieving efficient classification of remote sensing satellite images. The CNN-based models explored include ResNet, DenseNet, EfficientNet, VGG and InceptionV3. The models were evaluated on three publicly available EuroSAT, UCMerced-LandUse and NWPU-RESISC45 datasets containing categories of images. The models achieve promising results in accuracy, recall, precision and F1-score. This performance demonstrates the feasibility of Deep Learning approaches in learning the complex and in-homogeneous features of the high-resolution remote sensing images.},
  keywords = {Convolutional neural networks,Deep learning,Image classification,Remote sensing images,Satellite images,Vision Transformer},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\5RRFZJF3\\Adegun et al. - 2023 - Review of deep learning methods for remote sensing.pdf;C\:\\Users\\kraft\\Zotero\\storage\\NHRVA2UG\\s40537-023-00772-x.html}
}

@article{davydzenkaImprovingRemoteSensing2022,
  title = {Improving Remote Sensing Classification: {{A}} Deep-Learning-Assisted Model},
  shorttitle = {Improving Remote Sensing Classification},
  author = {Davydzenka, Tsimur and Tahmasebi, Pejman and Carroll, Mark},
  date = {2022-07-01},
  journaltitle = {Computers \& Geosciences},
  shortjournal = {Computers \& Geosciences},
  volume = {164},
  pages = {105123},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2022.105123},
  url = {https://www.sciencedirect.com/science/article/pii/S0098300422000814},
  urldate = {2024-12-10},
  abstract = {In many industries and applications, obtaining and classifying remote sensing imagery plays a crucial role. The accuracy of classification, in particular the machine learning methods, mainly depends on a multitude of factors, among which one of the most important ones is the amount of training data. Obtaining sufficient amounts of training data, however, can be very difficult or costly, and one must find alternative ways to improve the accuracy of predictions. To this end, a possible solution that we provide in this study is to use a stochastic method for producing variations of the training images that will retain the important class-wide features and thereby enrich the machine learning's “understanding” of the variabilities. As such, we applied a stochastic algorithm to produce additional realizations of the limited input imagery and thereby significantly increase the final overall accuracy in a deep learning method. We found that by enlarging the initial training set by additional realizations, we are able to consistently improve classification accuracy, compared with generic image augmentation approaches. The results of this study show that there is a great opportunity to increase the accuracy of predictions when enough data are not available.},
  keywords = {Data augmentation,Image classification,Machine learning,Remote sensing. introduction}
}

@online{DeeplearningmodelsREADMEmdMaster,
  title = {Deep-Learning-Models/{{README}}.Md at Master · Fchollet/Deep-Learning-Models},
  url = {https://github.com/fchollet/deep-learning-models/blob/master/README.md},
  urldate = {2024-12-10},
  file = {C:\Users\kraft\Zotero\storage\RECC7SU6\README.html}
}

@book{Goodfellow-et-al-201,
  title = {Deep {{Learning}}},
  author = {Goodfellow, Ian and Benigo, Yoshua and Courville, Aaron},
  date = {2016},
  publisher = {MIT Press},
  url = {http://www.deeplearningbook.org}
}

@online{heDeepResidualLearning2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2015-12-10},
  eprint = {1512.03385},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1512.03385},
  url = {http://arxiv.org/abs/1512.03385},
  urldate = {2024-12-10},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\9RHZS6WV\\He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf;C\:\\Users\\kraft\\Zotero\\storage\\ZNMVPPLM\\1512.html}
}

@article{liDeepLearningRemote2018,
  title = {Deep Learning for Remote Sensing Image Classification: {{A}} Survey},
  shorttitle = {Deep Learning for Remote Sensing Image Classification},
  author = {Li, Ying and Zhang, Haokui and Xue, Xizhe and Jiang, Yenan and Shen, Qiang},
  date = {2018},
  journaltitle = {WIREs Data Mining and Knowledge Discovery},
  volume = {8},
  number = {6},
  pages = {e1264},
  issn = {1942-4795},
  doi = {10.1002/widm.1264},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1264},
  urldate = {2024-12-10},
  abstract = {Remote sensing (RS) image classification plays an important role in the earth observation technology using RS data, having been widely exploited in both military and civil fields. However, due to the characteristics of RS data such as high dimensionality and relatively small amounts of labeled samples available, performing RS image classification faces great scientific and practical challenges. In recent years, as new deep learning (DL) techniques emerge, approaches to RS image classification with DL have achieved significant breakthroughs, offering novel opportunities for the research and development of RS image classification. In this paper, a brief overview of typical DL models is presented first. This is followed by a systematic review of pixel-wise and scene-wise RS image classification approaches that are based on the use of DL. A comparative analysis regarding the performances of typical DL-based RS methods is also provided. Finally, the challenges and potential directions for further research are discussed. This article is categorized under: Application Areas {$>$} Science and Technology Technologies {$>$} Classification},
  langid = {english},
  keywords = {convolutional neural network,deep belief network,deep learning,pixel-wise classification,remote sensing image,scene classification,stacked auto-encoder},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\CLS243QC\\Li et al. - 2018 - Deep learning for remote sensing image classificat.pdf;C\:\\Users\\kraft\\Zotero\\storage\\RNWM2CRC\\widm.html}
}

@online{RecipeTrainingNeural,
  title = {A {{Recipe}} for {{Training Neural Networks}}},
  url = {https://karpathy.github.io/2019/04/25/recipe/},
  urldate = {2024-12-13},
  file = {C:\Users\kraft\Zotero\storage\T6RG58J7\recipe.html}
}

@online{ResNetPyTorchREADMEmdMaster,
  title = {{{ResNet-PyTorch}}/{{README}}.Md at Master · {{JayPatwardhan}}/{{ResNet-PyTorch}}},
  url = {https://github.com/JayPatwardhan/ResNet-PyTorch/blob/master/README.md},
  urldate = {2024-12-10},
  file = {C:\Users\kraft\Zotero\storage\66ZIIF66\README.html}
}

@software{SatelliteimagedeeplearningTechniques2024,
  title = {Satellite-Image-Deep-Learning/Techniques},
  date = {2024-11-15T07:17:33Z},
  origdate = {2018-04-16T08:42:09Z},
  url = {https://github.com/satellite-image-deep-learning/techniques},
  urldate = {2024-11-15},
  abstract = {Techniques for deep learning with satellite \& aerial imagery},
  organization = {satellite-image-deep-learning},
  keywords = {convolutional-neural-networks,dataset,datasets,deep-learning,deep-neural-networks,earth-observation,image-classification,keras,machine-learning,object-detection,python,pytorch,remote-sensing,satellite-data,satellite-imagery,satellite-images,sentinel,tensorflow}
}

@online{ScikitlearnMachineLearning,
  title = {Scikit-Learn: Machine Learning in {{Python}}},
  url = {https://scikit-learn.org/stable/},
  urldate = {2025-01-15},
  file = {C:\Users\kraft\Zotero\storage\2BVVNTFF\stable.html}
}

@online{simonyanVeryDeepConvolutional2015,
  title = {Very {{Deep Convolutional Networks}} for {{Large-Scale Image Recognition}}},
  author = {Simonyan, Karen and Zisserman, Andrew},
  date = {2015-04-10},
  eprint = {1409.1556},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1409.1556},
  url = {http://arxiv.org/abs/1409.1556},
  urldate = {2024-12-10},
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\FPXFNITT\\Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf;C\:\\Users\\kraft\\Zotero\\storage\\6J7UKGFV\\1409.html}
}

@article{singhPixelBasedClassification2021a,
  title = {Pixel Based Classification for {{Landsat}} 8 {{OLI}} Multispectral Satellite Images Using Deep Learning Neural Network},
  author = {Singh, Mohan and Tyagi, Kapil Dev},
  date = {2021-11-01},
  journaltitle = {Remote Sensing Applications: Society and Environment},
  shortjournal = {Remote Sensing Applications: Society and Environment},
  volume = {24},
  pages = {100645},
  issn = {2352-9385},
  doi = {10.1016/j.rsase.2021.100645},
  url = {https://www.sciencedirect.com/science/article/pii/S2352938521001816},
  urldate = {2024-11-15},
  abstract = {In satellite image analysis, classification of objects appearing in an image is a major step of information extraction. The information acquired from the satellite image can be used to provide the solution of various remote sensing problems such as agricultural challenges, natural hazards, and environmental monitoring etc. The most of the conventional classifiers used to classify satellite images do not provide realistic classification with high accuracy. Therefore, for achieving realistic and more accurate classification of the satellite images is still a challenging task. Machine intelligence is being harnessed to solve this task. In this paper, we present a novel machine intelligence pixel based approach for multispectral satellite image classification. We have proposed a machine intelligence deep learning neural network with five hidden layers and seven training features for satellite images classification. The model is tested on four types of data sets namely three classes, four classes, five classes and seven classes. Accuracy of 99.99\%, 99.96\%, 99.45\% and 98.03\% has been obtained on four test data sets respectively. In all cases, it is observed that the proposed method provides 8.52\% higher accuracy than previously proposed classifiers.},
  keywords = {Artificial neural network (ANN),Deep learning and remote sensing,Landsat 8 OLI image dataset,Pixel based classification},
  file = {C:\Users\kraft\Zotero\storage\2Q926B5H\S2352938521001816.html}
}

@dataset{swisstopoSWISSIMAGERS2024,
  title = {{{SWISSIMAGE RS}}},
  author = {SwissTopo},
  date = {2024},
  url = {https://www.swisstopo.admin.ch/de/orthobilder-swissimage-rs},
  urldate = {2024-11-15},
  abstract = {Das Bildprodukt SWISSIMAGE RS enthält eine bisher unerreichte Informationsfülle. Durch die Kombination von vier Kanälen (Nahes Infrarot, Rot, Grün, Blau) bieten diese Einzelorthofotos eine optimale Grundlage für verschiedenste Fachanwendungen.},
  file = {C:\Users\kraft\Zotero\storage\86KKSQYE\orthobilder-swissimage-rs.html}
}

@article{thapaDeepLearningRemote2023,
  title = {Deep {{Learning}} for {{Remote Sensing Image Scene Classification}}: {{A Review}} and {{Meta-Analysis}}},
  shorttitle = {Deep {{Learning}} for {{Remote Sensing Image Scene Classification}}},
  author = {Thapa, Aakash and Horanont, Teerayut and Neupane, Bipul and Aryal, Jagannath},
  date = {2023-01},
  journaltitle = {Remote Sensing},
  volume = {15},
  number = {19},
  pages = {4804},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs15194804},
  url = {https://www.mdpi.com/2072-4292/15/19/4804},
  urldate = {2024-12-10},
  abstract = {Remote sensing image scene classification with deep learning (DL) is a rapidly growing field that has gained significant attention in the past few years. While previous review papers in this domain have been confined to 2020, an up-to-date review to show the progression of research extending into the present phase is lacking. In this review, we explore the recent articles, providing a thorough classification of approaches into three main categories: Convolutional Neural Network (CNN)-based, Vision Transformer (ViT)-based, and Generative Adversarial Network (GAN)-based architectures. Notably, within the CNN-based category, we further refine the classification based on specific methodologies and techniques employed. In addition, a novel and rigorous meta-analysis is performed to synthesize and analyze the findings from 50 peer-reviewed journal articles to provide valuable insights in this domain, surpassing the scope of existing review articles. Our meta-analysis shows that the most adopted remote sensing scene datasets are AID (41 articles) and NWPU-RESISC45 (40). A notable paradigm shift is seen towards the use of transformer-based models (6) starting from 2021. Furthermore, we critically discuss the findings from the review and meta-analysis, identifying challenges and future opportunities for improvement in this domain. Our up-to-date study serves as an invaluable resource for researchers seeking to contribute to this growing area of research.},
  issue = {19},
  langid = {english},
  keywords = {convolutional neural networks,deep learning,meta-analysis,remote sensing,scene classification},
  file = {C:\Users\kraft\Zotero\storage\SPZWVD52\Thapa et al. - 2023 - Deep Learning for Remote Sensing Image Scene Class.pdf}
}

@online{VisionTorchvisionModels,
  title = {Vision/Torchvision/Models/Vgg.Py at Main · Pytorch/Vision},
  url = {https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py},
  urldate = {2024-12-10},
  abstract = {Datasets, Transforms and Models specific to Computer Vision - pytorch/vision},
  langid = {english},
  organization = {GitHub}
}

@online{VisionTorchvisionModelsa,
  title = {Vision/Torchvision/Models/Resnet.Py at Main · Pytorch/Vision},
  url = {https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py},
  urldate = {2024-12-13},
  abstract = {Datasets, Transforms and Models specific to Computer Vision - pytorch/vision},
  langid = {english},
  organization = {GitHub}
}

@article{xieScaleFreeConvolutionalNeural2019,
  title = {Scale-{{Free Convolutional Neural Network}} for {{Remote Sensing Scene Classification}}},
  author = {Xie, Jie and He, Nanjun and Fang, Leyuan and Plaza, Antonio},
  date = {2019-09},
  journaltitle = {IEEE Transactions on Geoscience and Remote Sensing},
  volume = {57},
  number = {9},
  pages = {6916--6928},
  issn = {1558-0644},
  doi = {10.1109/TGRS.2019.2909695},
  url = {https://ieeexplore.ieee.org/abstract/document/8699111},
  urldate = {2024-12-10},
  abstract = {Fine-tuning of pretrained convolutional neural networks (CNNs) has been proven to be an effective strategy for remote sensing image scene classification, particularly when a limited number of labeled data sets are available for training purposes. However, such a fine-tuning process often needs that the input images are resized into a fixed size to generate input vectors of the size required by fully connected layers (FCLs) in the pretrained CNN model. Such a resizing process often discards key information in the scenes and thus deteriorates the classification performance. To address this issue, in this paper, we introduce a scale-free CNN (SF-CNN) for remote sensing scene classification. Specifically, the FCLs in the CNN model are first converted into convolutional layers, which not only allow the input images to be of arbitrary sizes but also retain the ability to extract discriminative features using a traditional sliding-window-based strategy. Then, a global average pooling (GAP) layer is added after the final convolutional layer so that input images of arbitrary size can be mapped to feature maps of uniform size. Finally, we utilize the resulting feature maps to create a new FCL that is fed to a softmax layer for final classification. Our experimental results conducted using several real data sets demonstrate the superiority of the proposed SF-CNN method over several well-known classification methods, including pretrained CNN-based ones.},
  eventtitle = {{{IEEE Transactions}} on {{Geoscience}} and {{Remote Sensing}}},
  keywords = {Data models,Feature extraction,Free-scale convolutional neural networks (CNNs),fully connected layers (FCLs),Image color analysis,Iron,Kernel,Remote sensing,remote sensing scene classification,Semantics},
  file = {C\:\\Users\\kraft\\Zotero\\storage\\MMUBGZ2M\\Xie et al. - 2019 - Scale-Free Convolutional Neural Network for Remote.pdf;C\:\\Users\\kraft\\Zotero\\storage\\BGYY79MZ\\8699111.html}
}
