% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 02_methods
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Methods}
\label{methods}

\subsection{Data}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The data used for this project is the SwissImage RS \autocite{swisstopoSWISSIMAGERS2024}
data from the Swiss Federal Office of Topography (SwissTopo).
It is a raster dataset with a resolution of 0.1 m containing four bands: RGB and NIR.
To cover the area of interest (AOI), six tiles of the dataset are needed.
Over this large AOI, there are three areas labeled with the corresponding labels \autoref{fig:aoi_labeled}.
These labels were provided by a team of researchers from the ZHAW. The three
areas are distributed over a residential area (83,487 m\textsuperscript{2}),
an industrial area (132,642 m\textsuperscript{2}), and a rural area (82,740 m\textsuperscript{2}).
Two kinds of labels are available: the land cover category \autoref{fig:category_areas} and an assessment of the 
degree of perviousness \autoref{fig:sealed_areas}. In \autoref{fig:label_distribution}, the distribution of
the data available for each label is shown for both the land cover category (\texttt{category}) and the sealing assessment (\texttt{sealed}).
A third kind of label was generated by simplifying the degree of perviousness into two classes: pervious and impervious (\texttt{sealed\_simple}).
This was done by reclassifying the unknown areas to sealed ones since they only consist of BuildingDistortions and
ConstructionSites.

\begin{figure}[H]
    \centering
    \captionsetup{width=0.8\linewidth}
    \includegraphics[scale=0.9, trim=-1.1cm 2cm 0cm 2cm, clip]{figures/map_aoi.pdf}
    \caption{Map of the AOI, Pratteln, a municipality in the canton of Basel-Landschaft, Switzerland. 
    The three marked areas, each split into four tiles, are the areas with corresponding labels. 1 - 4 are in the rural area,
    5 - 8 in the residential area, and 9 - 12 in the industrial area.}
    \label{fig:aoi_labeled}
\end{figure}

\begin{figure}[H]
    \centering
    \captionsetup{width=0.8\linewidth}
    \includegraphics[width=\linewidth]{figures/map_aoi_category.pdf}
    \caption{The three areas with the corresponding land cover categories.}
    \label{fig:category_areas}
\end{figure}

\begin{figure}[H]
    \centering
    \captionsetup{width=0.8\linewidth}
    \includegraphics[width=\linewidth]{figures/map_aoi_sealing.pdf}
    \caption{The three areas with the corresponding degree of perviousness.}
    \label{fig:sealed_areas}
\end{figure}

\begin{figure}[H]
    \centering
    \captionsetup{width=0.8\linewidth}
    \includegraphics{figures/area_by_category_and_seal.pdf}
    \caption{Available data by label, colored by the area.}
    \label{fig:label_distribution}
\end{figure}

\subsection{Programming Language and Frameworks}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

To build and train the deep learning model, the programming language Python was used.
The frameworks PyTorch and Lightning are widely used and powerful tools for building
deep learning models.

\subsection{Model Architecture}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For this study, an adapted version of the ResNet-18 architecture was used to classify 
aerial imagery with high spatial resolution. ResNet-18 is a CNN model 
using residual connections to solve the issue of vanishing
gradients during training. The residual connections allow the model to learn
deep representations, reducing the risk of overfitting.

To make the model suitable for the given problem with the available data, some 
modifications to the standard ResNet-18 architecture were necessary:

\begin{itemize}
    \item \textbf{Input Channels}: The original ResNet-18 was modified to work with four input 
    channels (e.g., red, green, blue, and near-infrared bands) instead of the standard
    three channels (RGB). Adding this fourth channel provides essential spectral
    information. The NIR is especially suited to detect vegetation \autocite{rouseMonitoringVegetationSystems1974}, 
    presumably aiding significantly in the classification of pervious surfaces.

    \item \textbf{Layer Configuration}: To adjust for the limited data available, one
    of the usually four fully connected layers was removed from the model, and the
    number of planes per block was reduced significantly from 64, 128, 256, 512 to 4, 8, 16.

    \item \textbf{Output Design}: Originally, the ResNet-18 model was designed for image
    classification tasks, outputting a single label for the whole image. Due to
    efficiency reasons, the model was adapted to output a patch of pixels instead.
    For this, the last fully connected layer was replaced with a convolutional layer
    mapping the output to a patch of pixels. The size of the output patch is adjustable
    via the \texttt{output\_patch\_size} parameter.
\end{itemize}    

Some batch normalization layers help to stabilize the training and improve generalization.
For the training, the AdamW optimizer was used, which combines adaptive learning
rate methods with weight decay for regularization. The model was trained using
a weighted cross-entropy loss function to handle class imbalances effectively.

The modified ResNet-18 model was implemented using PyTorch and was trained using 
the Lightning framework, which provides a high-level interface for PyTorch
and is quite accessible even for beginners.

\subsection{Data Processing and Augmentation}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

To feed data into the neural network, it is necessary to process it into a format that can be used for training.
A standardized sample size is needed to ensure that the model can be trained on the data.

\subsubsection{Preprocessing}%---------------------------------------
In the first step, the data was processed using ArcGIS Pro. The process included several steps implemented as
a model with the Model Builder \autoref{fig:processing_model}. The six tiles were mosaicked together, and the area of interest 
was clipped. The area labels 1 - 12 and both versions of available data labels were transformed to raster datasets
and added as additional bands to the dataset. The data was then exported as a GeoTIFF file.
To use the data in a neural network, an additional step was necessary. Using Python,
the data was transformed into Zarr format. This format is a chunked, compressed, N-dimensional array
storage format with multi-scale support. This allows for lazy loading and therefore for more memory-
efficient data access during training.

\begin{figure}[H]
    \centering
    \captionsetup{width=0.8\linewidth}
    \includegraphics[width=\linewidth]{figures/ArcGIS_Model.png}
    \caption{ArcGIS model used for preprocessing the data.}
    \label{fig:processing_model}
\end{figure}

\subsubsection{Processing and Augmentation}%-------------------------------

To feed the data into a neural network, a PyTorch DataLoader was implemented.
The data was sampled as cutouts of size 51x51 pixels, predicting the 5x5 center pixels as output.
This cutout size and output size were implemented as a parameter, 
but no other values were tested.
The DataLoader indexes the available data depending on the cutout size and the 
corresponding area labels depending on the purpose:

\begin{tabular}{ll}
    \hspace{1.2em}\textbullet\ Areas for Training:   & 1, 2, 5, 6, 9, 10 \\
    \hspace{1.2em}\textbullet\ Areas for Validation: & 3, 7, 11          \\
    \hspace{1.2em}\textbullet\ Areas for Testing:    & 4, 8, 12          \\
\end{tabular}

It handles the data augmentation on the fly, during training steps.
For the data augmentation, a parent class BaseAugmentor was implemented from which the different augmentors inherit. 
The implemented augmentors - refer to \autoref{tab:augmentors} - are then chained into an object of the class AugmentorChain
which can be used in the DataLoader. Only the Flip- and RotateAugmentor were used for the training of the models.

\begin{table}[H]
    \centering
    \caption{Implemented augmentors}
    \label{tab:augmentors}
        \begin{tabular}{ll}
        \toprule
        \textbf{Augmentor} & \textbf{Description} \\
        \midrule
        FlipAugmentor & Randomly flips the image vertically and horizontally\\
        RotateAugmentor & Randomly rotates the image 0, 90, 180 or 270Â° \\
        PixelNoiseAugmentor & Adds random noise to the image (parameter: scale) \\
        ChannelNoiseAugmentor & Adds random noise to the channels (parameter: scale) \\
        \bottomrule
        \end{tabular}
\end{table}

\subsection{Fitting the Model}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Fitting the model was done on the IUNR HPC cluster using node 301, an HPE Apollo 6500 Gen10+ 
node running Rocky Linux 8. The node is equipped with 8 NVIDIA L40S GPUs (48 GB each), 
dual AMD EPYC 7742 processors, 512 cores, and 5800 GB of storage, 
providing the computational power needed for high-performance tasks.
The training was done using a potential limit of 300 epochs and an early stopping callback
set to stop after 10 epochs without improvement. Batch size was set to 128 for training and 256 for validation and prediction.
During training, only the best model and the last model were saved.
Upon completion of the training, the best model was loaded and used for prediction on the whole dataset.
These predictions were saved as a Zarr file for later use in the evaluation.
For both the category classification and the perviousness classification, two models were trained
with and without data augmentation. The data augmentation was done using the Flip- and RotateAugmentor.
The learning rate was set to 0.001 and weight decay to 0.01.

For the simplified perviousness classification, a limited hyperparameter search was conducted.
All combinations of the following parameters were tested:

\begin{tabular}{ll}
    \hspace{1.2em}\textbullet\ Learning rate:       & 0.001, 0.0001                                \\
    \hspace{1.2em}\textbullet\ Weight decay:        & 0, 0.1, 0.01                                 \\
    \hspace{1.2em}\textbullet\ Data augmentation:   & no augmentation, Flip- and RotateAugmentor    \\
\end{tabular}

\subsection{Evaluation}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For the performance evaluation of the models, the Python library Scikit-Learn was used. 
The predictions were loaded from the Zarr file and compared to the ground truth labels.
Accuracy, F1-Score (weighted and per class) were calculated for every model and stored in a CSV file
for later comparison. For the best model, the accuracy was also calculated, grouped by 
corresponding land cover category to provide insight into which category was classified best.
