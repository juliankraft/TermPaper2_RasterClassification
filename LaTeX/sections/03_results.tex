% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 03_results
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Results}
\label{results}

The best performing model achieved an accuracy of 0.927 and a weighted F1 Score of 0.927.
The results for all trained models are summarized in \autoref{tab:accuracy_f1_table}.
All trained models for the simplified perviousness lead the ranking, followed by the
models for the perviousness classification and the category classification
with accuracies of around 0.88 and 0.59, respectively. Only the label type \texttt{sealed\_simple}
will be considered for further analysis, as it is the most relevant for the study area.

\begin{table}[H]
    \centering
    \caption{Accuracy and F1 Score for all trained models, arranged by accuracy.}
    \small
    \label{tab:accuracy_f1_table}
    \begin{tabular}{llllll}
    \toprule
    LabelType & Augmented & LearningRate & WeightDecay & Accuracy & F1 Score \\
    \midrule
    sealed\_simple  & True      & 0.0001    & 0.1   & 0.9274    & 0.9275 \\
    sealed\_simple  & False     & 0.0001    & 0.01  & 0.9109    & 0.9112 \\
    sealed\_simple  & True      & 0.001     & 0.1   & 0.9069    & 0.9072 \\
    sealed\_simple  & True      & 0.0001    & 0.01  & 0.9034    & 0.9038 \\
    sealed\_simple  & True      & 0.001     & 0     & 0.9028    & 0.9032 \\
    sealed\_simple  & False     & 0.001     & 0.1   & 0.9021    & 0.9024 \\
    sealed\_simple  & True      & 0.0001    & 0     & 0.9007    & 0.9011 \\
    sealed\_simple  & False     & 0.0001    & 0.1   & 0.9000    & 0.9004 \\
    sealed\_simple  & False     & 0.001     & 0.01  & 0.8999    & 0.9001 \\
    sealed\_simple  & False     & 0.001     & 0     & 0.8996    & 0.9000 \\
    sealed\_simple  & True      & 0.001     & 0.01  & 0.8980    & 0.8984 \\
    sealed\_simple  & False     & 0.0001    & 0     & 0.8977    & 0.8980 \\
    sealed          & False     & 0.001     & 0.01  & 0.8817    & 0.8716 \\
    sealed          & True      & 0.001     & 0.01  & 0.8763    & 0.8619 \\
    category        & True      & 0.001     & 0.01  & 0.5902    & 0.5722 \\
    category        & False     & 0.001     & 0.01  & 0.5806    & 0.5665 \\
    \bottomrule
    \end{tabular}
\end{table}

\subsection{Augmentation}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Hyperparameter Tuning}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[H]
    \centering
    \captionsetup{width=0.8\linewidth}
    \includegraphics{figures/hp_tuning_boxplot.pdf}
    \caption{Accuracy of the models for the different hyperparameter grouped by use of data augmentation.}
    \label{fig:hp_tuning_boxplot}
\end{figure}

\subsection{Best Model}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The best performing model was the one for the simplified perviousness classification
with the following hyperparameter:
\begin{itemize}
    \item Learning rate: 0.001
    \item Weight decay: 0.01
    \item Data augmentation applied
\end{itemize}
It achieved an accuracy of 0.927 and a weighted F1 Score of 0.927.
The F1 Score per class was 0.92 for class 'unsealed' and 0.93 for class 'sealed'.
The accuracy per category is shown in \autoref{fig:best_model_accuracy_per_category}.
For a visual inspection of the predictions refer to \autoref{fig:best_model_visual}.

\begin{figure}[H]
    \centering
    \captionsetup{width=0.8\linewidth}
    \includegraphics{figures/best_model_accuracy_per_category.pdf}
    \caption{Accuracy per category for the best performing model including relative count of available data for each category.}
    \label{fig:best_model_accuracy_per_category}
\end{figure}

\begin{figure}[H]
    \centering
    \captionsetup{width=0.8\linewidth}
    \includegraphics{figures/best_model_visual.pdf}
    \caption{Visual inspection of the predictions for the test areas of the best model.}
    \label{fig:best_model_visual}
\end{figure}